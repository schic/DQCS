<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
  <title>JBoss Tattletale 1.1.2.Final: hive-shims-common-1.2.1.jar</title>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8">
  <link rel="stylesheet" type="text/css" href="../style.css">
</head>
<body>

<h1>hive-shims-common-1.2.1.jar</h1>
<a href="../index.html">Main</a>
<p>
<table>
  <tr class="rowodd">
     <td>Name</td>
     <td>hive-shims-common-1.2.1.jar</td>
  </tr>
  <tr class="roweven">
     <td>Class Version</td>
     <td></td>
  </tr>
  <tr class="rowodd">
     <td>Locations</td>
     <td>       <table>
      <tr>
        <td>D:\DataCleaner-DataCleaner-5.1.0\desktop\ui\target\lib\hive-shims-common-1.2.1.jar</td>
        <td>1.2.1</td>
      </tr>
       </table>
</td>
  </tr>
  <tr class="roweven">
     <td>Profiles</td>
     <td>Sun Java 6  <tr class="rowodd">
     <td>Manifest</td>
     <td>Manifest-Version: 1.0<br>Implementation-Title: Hive Shims Common<br>Implementation-Version: 1.2.1<br>Archiver-Version: Plexus Archiver<br>Built-By: sush<br>Specification-Vendor: The Apache Software Foundation<br>Specification-Title: Hive Shims Common<br>Implementation-Vendor-Id: org.apache.hive.shims<br>Created-By: Apache Maven<br>Build-Jdk: 1.7.0_79<br>Specification-Version: 1.2.1<br>Implementation-Vendor: The Apache Software Foundation<br></td>
  </tr>
  <tr class="roweven">
     <td>Signing information</td>
     <td></td>
  </tr>
  <tr class="rowodd">
     <td>Requires</td>
     <td>com.google.common.annotations.VisibleForTesting<br>com.google.common.collect.MapMaker<br>java.io.ByteArrayInputStream<br>java.io.ByteArrayOutputStream<br>java.io.Closeable<br>java.io.DataInput<br>java.io.DataInputStream<br>java.io.DataOutput<br>java.io.DataOutputStream<br>java.io.IOException<br>java.io.InputStream<br>java.io.OutputStream<br>java.lang.AssertionError<br>java.lang.Boolean<br>java.lang.Class<br>java.lang.ClassNotFoundException<br>java.lang.Enum<br>java.lang.Exception<br>java.lang.IllegalAccessException<br>java.lang.IllegalArgumentException<br>java.lang.IllegalStateException<br>java.lang.Integer<br>java.lang.InterruptedException<br>java.lang.Math<br>java.lang.NoSuchFieldError<br>java.lang.NoSuchMethodException<br>java.lang.Object<br>java.lang.Runnable<br>java.lang.Runtime<br>java.lang.RuntimeException<br>java.lang.SecurityException<br>java.lang.String<br>java.lang.StringBuilder<br>java.lang.System<br>java.lang.Thread<br>java.lang.ThreadLocal<br>java.lang.Throwable<br>java.lang.UnsupportedOperationException<br>java.lang.Void<br>java.lang.reflect.Constructor<br>java.lang.reflect.InvocationTargetException<br>java.lang.reflect.Method<br>java.net.InetAddress<br>java.net.InetSocketAddress<br>java.net.MalformedURLException<br>java.net.Socket<br>java.net.URI<br>java.net.URISyntaxException<br>java.nio.ByteBuffer<br>java.security.AccessControlException<br>java.security.NoSuchAlgorithmException<br>java.security.PrivilegedAction<br>java.security.PrivilegedExceptionAction<br>java.util.ArrayList<br>java.util.Arrays<br>java.util.Collection<br>java.util.Collections<br>java.util.Comparator<br>java.util.HashMap<br>java.util.HashSet<br>java.util.Iterator<br>java.util.List<br>java.util.Locale<br>java.util.Map<br>java.util.Set<br>java.util.TreeMap<br>java.util.concurrent.ConcurrentHashMap<br>java.util.concurrent.ConcurrentMap<br>java.util.concurrent.atomic.AtomicInteger<br>javax.crypto.SecretKey<br>javax.security.auth.callback.Callback<br>javax.security.auth.callback.CallbackHandler<br>javax.security.auth.callback.NameCallback<br>javax.security.auth.callback.PasswordCallback<br>javax.security.auth.callback.UnsupportedCallbackException<br>javax.security.auth.login.AppConfigurationEntry<br>javax.security.auth.login.AppConfigurationEntry$LoginModuleControlFlag<br>javax.security.auth.login.Configuration<br>javax.security.auth.login.LoginException<br>javax.security.sasl.AuthorizeCallback<br>javax.security.sasl.RealmCallback<br>javax.security.sasl.RealmChoiceCallback<br>javax.security.sasl.SaslException<br>javax.security.sasl.SaslServer<br>org.apache.commons.codec.binary.Base64<br>org.apache.commons.lang.ArrayUtils<br>org.apache.commons.lang.StringUtils<br>org.apache.commons.logging.Log<br>org.apache.commons.logging.LogFactory<br>org.apache.curator.RetryPolicy<br>org.apache.curator.framework.CuratorFramework<br>org.apache.curator.framework.CuratorFrameworkFactory<br>org.apache.curator.framework.CuratorFrameworkFactory$Builder<br>org.apache.curator.framework.api.ACLBackgroundPathAndBytesable<br>org.apache.curator.framework.api.ACLProvider<br>org.apache.curator.framework.api.BackgroundPathAndBytesable<br>org.apache.curator.framework.api.CreateBuilder<br>org.apache.curator.framework.api.DeleteBuilder<br>org.apache.curator.framework.api.GetChildrenBuilder<br>org.apache.curator.framework.api.GetDataBuilder<br>org.apache.curator.framework.api.ProtectACLCreateModePathAndBytesable<br>org.apache.curator.framework.api.SetDataBuilder<br>org.apache.curator.framework.imps.CuratorFrameworkState<br>org.apache.curator.retry.ExponentialBackoffRetry<br>org.apache.hadoop.conf.Configurable<br>org.apache.hadoop.conf.Configuration<br>org.apache.hadoop.fs.BlockLocation<br>org.apache.hadoop.fs.ContentSummary<br>org.apache.hadoop.fs.FSDataInputStream<br>org.apache.hadoop.fs.FSDataOutputStream<br>org.apache.hadoop.fs.FileChecksum<br>org.apache.hadoop.fs.FileStatus<br>org.apache.hadoop.fs.FileSystem<br>org.apache.hadoop.fs.FilterFileSystem<br>org.apache.hadoop.fs.FsShell<br>org.apache.hadoop.fs.HarFileSystem<br>org.apache.hadoop.fs.LocalFileSystem<br>org.apache.hadoop.fs.Path<br>org.apache.hadoop.fs.PathFilter<br>org.apache.hadoop.fs.permission.FsAction<br>org.apache.hadoop.fs.permission.FsPermission<br>org.apache.hadoop.io.Text<br>org.apache.hadoop.io.Writable<br>org.apache.hadoop.io.WritableComparable<br>org.apache.hadoop.io.WritableUtils<br>org.apache.hadoop.mapred.ClusterStatus<br>org.apache.hadoop.mapred.FileInputFormat<br>org.apache.hadoop.mapred.InputSplit<br>org.apache.hadoop.mapred.JobConf<br>org.apache.hadoop.mapred.JobContext<br>org.apache.hadoop.mapred.JobID<br>org.apache.hadoop.mapred.JobProfile<br>org.apache.hadoop.mapred.JobStatus<br>org.apache.hadoop.mapred.RecordReader<br>org.apache.hadoop.mapred.Reporter<br>org.apache.hadoop.mapred.TaskAttemptContext<br>org.apache.hadoop.mapred.TaskAttemptID<br>org.apache.hadoop.mapred.lib.CombineFileInputFormat<br>org.apache.hadoop.mapred.lib.CombineFileSplit<br>org.apache.hadoop.mapreduce.Job<br>org.apache.hadoop.mapreduce.JobContext<br>org.apache.hadoop.mapreduce.JobID<br>org.apache.hadoop.mapreduce.OutputFormat<br>org.apache.hadoop.mapreduce.TaskAttemptContext<br>org.apache.hadoop.mapreduce.TaskAttemptID<br>org.apache.hadoop.mapreduce.TaskID<br>org.apache.hadoop.security.Credentials<br>org.apache.hadoop.security.SaslRpcServer<br>org.apache.hadoop.security.SaslRpcServer$AuthMethod<br>org.apache.hadoop.security.SaslRpcServer$SaslGssCallbackHandler<br>org.apache.hadoop.security.SecurityUtil<br>org.apache.hadoop.security.UserGroupInformation<br>org.apache.hadoop.security.UserGroupInformation$AuthenticationMethod<br>org.apache.hadoop.security.authentication.util.KerberosUtil<br>org.apache.hadoop.security.authorize.AuthorizationException<br>org.apache.hadoop.security.authorize.ProxyUsers<br>org.apache.hadoop.security.token.SecretManager<br>org.apache.hadoop.security.token.SecretManager$InvalidToken<br>org.apache.hadoop.security.token.Token<br>org.apache.hadoop.security.token.TokenIdentifier<br>org.apache.hadoop.security.token.TokenSelector<br>org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier<br>org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager<br>org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$DelegationTokenInformation<br>org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSelector<br>org.apache.hadoop.security.token.delegation.DelegationKey<br>org.apache.hadoop.util.Daemon<br>org.apache.hadoop.util.Progressable<br>org.apache.hadoop.util.ReflectionUtils<br>org.apache.hadoop.util.Shell<br>org.apache.hadoop.util.StringUtils<br>org.apache.hadoop.util.VersionInfo<br>org.apache.log4j.Appender<br>org.apache.log4j.AppenderSkeleton<br>org.apache.log4j.Layout<br>org.apache.log4j.spi.ErrorHandler<br>org.apache.log4j.spi.Filter<br>org.apache.log4j.spi.LoggingEvent<br>org.apache.log4j.spi.OptionHandler<br>org.apache.thrift.TException<br>org.apache.thrift.TProcessor<br>org.apache.thrift.protocol.TProtocol<br>org.apache.thrift.transport.TSaslClientTransport<br>org.apache.thrift.transport.TSaslServerTransport<br>org.apache.thrift.transport.TSaslServerTransport$Factory<br>org.apache.thrift.transport.TSocket<br>org.apache.thrift.transport.TTransport<br>org.apache.thrift.transport.TTransportException<br>org.apache.thrift.transport.TTransportFactory<br>org.apache.zookeeper.CreateMode<br>org.apache.zookeeper.KeeperException<br>org.apache.zookeeper.KeeperException$NoNodeException<br>org.apache.zookeeper.KeeperException$NodeExistsException<br>org.apache.zookeeper.ZooDefs<br>org.apache.zookeeper.ZooDefs$Ids<br>org.apache.zookeeper.data.ACL<br>org.apache.zookeeper.data.Id<br>org.slf4j.Logger<br>org.slf4j.LoggerFactory</td>
  </tr>
  <tr class="roweven">
     <td>Provides</td>
     <td>       <table>         <tr>
           <td>org.apache.hadoop.fs.DefaultFileAccess</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.fs.ProxyFileSystem</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.fs.ProxyLocalFileSystem</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.io.HiveIOExceptionHandler</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.io.HiveIOExceptionNextHandleResult</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.CombineHiveKey</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$ByteBufferPoolShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$CombineFileInputFormatShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$DirectCompressionType</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$DirectDecompressorShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$HCatHadoopShims</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$HCatHadoopShims$PropertyName</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$HdfsEncryptionShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$HdfsFileStatus</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$JobTrackerState</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$KerberosNameShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$MiniDFSShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$MiniMrShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$NoopHdfsEncryptionShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$StoragePolicyShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$StoragePolicyValue</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$WebHCatJTShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShims$ZeroCopyReaderShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShimsSecure</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileInputFormatShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShimsSecure$CombineFileRecordReader</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HadoopShimsSecure$InputSplitShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HiveEventCounter</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.HiveHarFileSystem</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.JettyShims</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.JettyShims$Server</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.SchedulerShim</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.ShimLoader</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.Utils</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.shims.Utils$JaasConfiguration</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.DBTokenStore</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.DelegationTokenIdentifier</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.DelegationTokenSecretManager</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.DelegationTokenSelector</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.DelegationTokenStore</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.DelegationTokenStore$TokenStoreException</td>
           <td>-8693819817623074083</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$1</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Client</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Client$SaslClientCallbackHandler</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$1</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$2</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$3</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$4</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$SaslDigestCallbackHandler</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$ServerMode</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingTransportFactory</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingTransportFactory$1</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.MemoryTokenStore</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.TFilterTransport</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.TUGIContainingTransport</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.TUGIContainingTransport$Factory</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.TokenStoreDelegationTokenSecretManager$ExpiredTokenRemover</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore$1</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.ZooKeeperTokenStore$2</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.client.TUGIAssumingTransport</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.hive.thrift.client.TUGIAssumingTransport$1</td>
           <td>&nbsp;</td>
         </tr>
         <tr>
           <td>org.apache.hadoop.security.token.delegation.HiveDelegationTokenSupport</td>
           <td>&nbsp;</td>
         </tr>
       </table></td>
  </tr>
</table>

<p>
<hr>
Generated by: <a href="http://www.jboss.org/projects/tattletale">JBoss Tattletale 1.1.2.Final</a>

</body>
</html>
